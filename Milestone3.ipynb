{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {},
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MILESTONE 3: TEXTMORPH - READABILITY, SUMMARIZATION & PARAPHRASING APPLICATION\n",
        "Developed the core TextMorph application with dynamic readability analysis, multi-level summarization, and complexity-based paraphrasing.\n",
        "Integrated secure user authentication, file/text upload, visual metrics, and side-by-side comparison of original and paraphrased text."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SECTION 1: Install Libraries"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m323.9/323.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit pyngrok bcrypt pyjwt pandas pypdf nltk transformers torch --quiet\n",
        "!pip install transformers torch sentencepiece\n",
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SECTION 2: Application"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app1.py\n",
        "import streamlit as st\n",
        "import sqlite3\n",
        "import bcrypt\n",
        "import pandas as pd\n",
        "import jwt\n",
        "from datetime import datetime, timedelta\n",
        "import numpy as np\n",
        "import time\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import smtplib\n",
        "import random\n",
        "from email.mime.text import MIMEText\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "import torch\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Try to install required PDF packages if not available\n",
        "try:\n",
        "    import PyPDF2\n",
        "except ImportError:\n",
        "    try:\n",
        "        import pypdf\n",
        "    except ImportError:\n",
        "        import subprocess\n",
        "        import sys\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pypdf\"])\n",
        "            import pypdf\n",
        "            st.success(\"‚úÖ pypdf installed successfully!\")\n",
        "        except:\n",
        "            st.warning(\"‚ö†Ô∏è Could not install pypdf automatically. Please run: pip install pypdf\")\n",
        "\n",
        "# Download required NLTK data with error handling\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt_tab')\n",
        "except LookupError:\n",
        "    try:\n",
        "        nltk.download('punkt_tab', quiet=True)\n",
        "    except:\n",
        "        st.error(\"NLTK data download failed. Using fallback tokenization.\")\n",
        "\n",
        "# =============================================================================\n",
        "#  CONFIGURATION & CONSTANTS\n",
        "# =============================================================================\n",
        "\n",
        "SECRET_KEY = \"your-long-and-very-secret-key-for-jwt-goes-here\"\n",
        "\n",
        "# Email configuration for OTP\n",
        "EMAIL_CONFIG = {\n",
        "    'smtp_server': 'smtp.gmail.com',\n",
        "    'smtp_port': 587,\n",
        "    'sender_email': 'ur email id',  # ‚ö†Ô∏è REPLACE WITH YOUR EMAIL ‚ö†Ô∏è\n",
        "    'sender_password': 'app password'   # ‚ö†Ô∏è REPLACE WITH YOUR APP PASSWORD ‚ö†Ô∏è\n",
        "}\n",
        "\n",
        "# =============================================================================\n",
        "#  INSTANT MODEL LOADING FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "@st.cache_resource\n",
        "def load_summarization_model(model_type):\n",
        "    \"\"\"Load summarization models instantly\"\"\"\n",
        "    try:\n",
        "        # Use the fastest available models\n",
        "        if model_type == \"BART\":\n",
        "            model_name = \"sshleifer/distilbart-cnn-12-6\"\n",
        "        elif model_type == \"Pegasus\":\n",
        "            model_name = \"google/pegasus-cnn_dailymail\"\n",
        "        elif model_type == \"FLAN-T5\":\n",
        "            model_name = \"google/flan-t5-small\"\n",
        "        else:\n",
        "            model_name = \"sshleifer/distilbart-cnn-12-6\"\n",
        "\n",
        "        summarizer = pipeline(\n",
        "            \"summarization\",\n",
        "            model=model_name,\n",
        "            tokenizer=model_name,\n",
        "            torch_dtype=torch.float32\n",
        "        )\n",
        "        return summarizer\n",
        "    except Exception as e:\n",
        "        st.error(f\"‚ùå Failed to load {model_type} model: {e}\")\n",
        "        return None\n",
        "\n",
        "@st.cache_resource\n",
        "def load_paraphrase_model():\n",
        "    \"\"\"Load paraphrase model instantly\"\"\"\n",
        "    try:\n",
        "        model_name = \"t5-small\"\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "        return model, tokenizer\n",
        "    except Exception as e:\n",
        "        st.error(f\"‚ùå Failed to load paraphrase model: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def local_summarize(_summarizer, text, summary_length):\n",
        "    \"\"\"Summarize text using local model\"\"\"\n",
        "    if _summarizer is None:\n",
        "        return \"Summarization model not available. Please try again.\"\n",
        "\n",
        "    # Configure length\n",
        "    length_config = {\n",
        "        \"Short\": {\"max_length\": 80, \"min_length\": 30},\n",
        "        \"Medium\": {\"max_length\": 120, \"min_length\": 50},\n",
        "        \"Long\": {\"max_length\": 150, \"min_length\": 70}\n",
        "    }\n",
        "\n",
        "    config = length_config[summary_length]\n",
        "\n",
        "    try:\n",
        "        # Process text efficiently\n",
        "        if len(text) > 1024:\n",
        "            text = text[:1024]\n",
        "\n",
        "        result = _summarizer(\n",
        "            text,\n",
        "            max_length=config[\"max_length\"],\n",
        "            min_length=config[\"min_length\"],\n",
        "            do_sample=False\n",
        "        )\n",
        "        return result[0]['summary_text']\n",
        "    except Exception as e:\n",
        "        return f\"Summarization error: {str(e)}\"\n",
        "\n",
        "def local_paraphrase(_model, _tokenizer, text, complexity, style):\n",
        "    \"\"\"Paraphrase text using local model\"\"\"\n",
        "    if _model is None or _tokenizer is None:\n",
        "        return \"Paraphrase model not available. Please try again.\"\n",
        "\n",
        "    try:\n",
        "        # Create prompt based on complexity and style\n",
        "        if complexity == \"Beginner\":\n",
        "            prompt = f\"Simplify this text for beginners: {text}\"\n",
        "        elif complexity == \"Intermediate\":\n",
        "            prompt = f\"Paraphrase this text clearly: {text}\"\n",
        "        elif complexity == \"Advanced\":\n",
        "            prompt = f\"Rephrase this text with more advanced vocabulary: {text}\"\n",
        "        else:  # Expert\n",
        "            prompt = f\"Rephrase this text for expert audience using technical language: {text}\"\n",
        "\n",
        "        # Add style-specific instructions\n",
        "        if style == \"Simplification\":\n",
        "            prompt = f\"Simplify and make this text easier to understand: {text}\"\n",
        "        elif style == \"Formalization\":\n",
        "            prompt = f\"Make this text more formal and professional: {text}\"\n",
        "\n",
        "        # Tokenize and generate\n",
        "        inputs = _tokenizer.encode(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = _model.generate(\n",
        "                inputs,\n",
        "                max_length=len(text) + 100,\n",
        "                min_length=max(20, len(text) // 2),\n",
        "                num_beams=4,\n",
        "                early_stopping=True,\n",
        "                temperature=0.7\n",
        "            )\n",
        "\n",
        "        paraphrased = _tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        return f\"[FLAN-T5] {paraphrased}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Paraphrasing error: {str(e)}\"\n",
        "\n",
        "def calculate_flesch_kincaid_para(text):\n",
        "    \"\"\"Calculate approximate Flesch-Kincaid grade level for paraphrasing\"\"\"\n",
        "    try:\n",
        "        sentences = len(re.split(r'[.!?]+', text))\n",
        "        words = len(text.split())\n",
        "        syllables = sum(len(re.findall(r'[aeiouy]+', word.lower())) for word in text.split())\n",
        "\n",
        "        if sentences == 0 or words == 0:\n",
        "            return 8.0\n",
        "\n",
        "        avg_sentence_length = words / sentences\n",
        "        avg_syllables_per_word = syllables / words\n",
        "\n",
        "        grade = 0.39 * avg_sentence_length + 11.8 * avg_syllables_per_word - 15.59\n",
        "        return max(1.0, min(20.0, grade))\n",
        "    except:\n",
        "        return 8.0\n",
        "\n",
        "# Fallback tokenization functions\n",
        "def simple_sent_tokenize(text):\n",
        "    \"\"\"Simple sentence tokenizer as fallback\"\"\"\n",
        "    try:\n",
        "        return sent_tokenize(text)\n",
        "    except:\n",
        "        # Fallback: split on common sentence endings\n",
        "        import re\n",
        "        sentences = re.split(r'[.!?]+', text)\n",
        "        return [s.strip() for s in sentences if s.strip()]\n",
        "\n",
        "def simple_word_tokenize(text):\n",
        "    \"\"\"Simple word tokenizer as fallback\"\"\"\n",
        "    try:\n",
        "        return word_tokenize(text)\n",
        "    except:\n",
        "        # Fallback: split on whitespace and punctuation\n",
        "        import re\n",
        "        words = re.findall(r'\\b\\w+\\b', text)\n",
        "        return words\n",
        "\n",
        "# --- 1. Page Configuration ---\n",
        "st.set_page_config(\n",
        "    page_title=\"LLM AI\",\n",
        "    layout=\"wide\",\n",
        ")\n",
        "\n",
        "# --- 2. Custom CSS for Styling ---\n",
        "custom_css = \"\"\"\n",
        "<style>\n",
        "    /* Center the main content when not logged in */\n",
        "    .main .block-container {\n",
        "        max-width: 550px;\n",
        "        padding-top: 2rem;\n",
        "    }\n",
        "    /* Style the header */\n",
        "    h1 {\n",
        "        background-color: #0d6efd;\n",
        "        color: white;\n",
        "        padding: 1rem;\n",
        "        border-radius: 10px 10px 0 0;\n",
        "        text-align: left;\n",
        "        font-size: 24px;\n",
        "        margin-bottom: 0 !important;\n",
        "    }\n",
        "    /* Style the form container */\n",
        "    div[data-testid=\"stTabs\"] {\n",
        "        border: 1px solid #E0E0E0;\n",
        "        border-radius: 0 0 10px 10px;\n",
        "        padding: 1.5rem;\n",
        "        box-shadow: 0 4px 8px rgba(0,0,0,0.05);\n",
        "        background-color: white;\n",
        "    }\n",
        "    /* Style the submit button */\n",
        "    .stButton>button {\n",
        "        width: 100%;\n",
        "        background-color: #0d6efd;\n",
        "        color: white;\n",
        "        border-radius: 6px;\n",
        "    }\n",
        "    /* Key features box */\n",
        "    .key-features {\n",
        "        background-color: #E7F3FF;\n",
        "        border-left: 5px solid #0d6efd;\n",
        "        padding: 1rem;\n",
        "        margin-top: 1rem;\n",
        "        border-radius: 5px;\n",
        "    }\n",
        "    /* Dashboard styling */\n",
        "    .metric-card {\n",
        "        background-color: #f8f9fa;\n",
        "        border-radius: 10px;\n",
        "        padding: 1rem;\n",
        "        text-align: center;\n",
        "        border-left: 4px solid #0d6efd;\n",
        "    }\n",
        "    .metric-value {\n",
        "        font-size: 24px;\n",
        "        font-weight: bold;\n",
        "        color: #0d6efd;\n",
        "    }\n",
        "    .metric-label {\n",
        "        font-size: 14px;\n",
        "        color: #6c757d;\n",
        "    }\n",
        "    /* Simplified Upload box styling */\n",
        "    .upload-box {\n",
        "        border: 2px dashed #0d6efd;\n",
        "        border-radius: 15px;\n",
        "        padding: 3rem 2rem;\n",
        "        background-color: #f8f9fa;\n",
        "        text-align: center;\n",
        "        margin: 1rem 0;\n",
        "        min-height: 150px;\n",
        "        display: flex;\n",
        "        flex-direction: column;\n",
        "        justify-content: center;\n",
        "        align-items: center;\n",
        "    }\n",
        "    .upload-box h3 {\n",
        "        margin-bottom: 0.5rem;\n",
        "        color: #0d6efd;\n",
        "    }\n",
        "    .upload-box p {\n",
        "        margin: 0;\n",
        "        color: #6c757d;\n",
        "        font-size: 14px;\n",
        "    }\n",
        "    /* File name display */\n",
        "    .file-name {\n",
        "        background-color: #e9ecef;\n",
        "        border-radius: 8px;\n",
        "        padding: 0.5rem 1rem;\n",
        "        margin-top: 1rem;\n",
        "        font-weight: bold;\n",
        "        color: #495057;\n",
        "    }\n",
        "    /* Navigation menu styling */\n",
        "    .nav-button {\n",
        "        width: 100%;\n",
        "        text-align: left;\n",
        "        padding: 0.75rem 1rem;\n",
        "        margin: 0.25rem 0;\n",
        "        border: none;\n",
        "        background: transparent;\n",
        "        border-radius: 8px;\n",
        "        cursor: pointer;\n",
        "        transition: all 0.3s ease;\n",
        "    }\n",
        "    .nav-button:hover {\n",
        "        background-color: #e9ecef;\n",
        "    }\n",
        "    .nav-button.active {\n",
        "        background-color: #0d6efd;\n",
        "        color: white;\n",
        "    }\n",
        "    .text-input-area {\n",
        "        border: 1px solid #dee2e6;\n",
        "        border-radius: 8px;\n",
        "        padding: 1rem;\n",
        "        background-color: #f8f9fa;\n",
        "    }\n",
        "</style>\n",
        "\"\"\"\n",
        "dark_theme_css = \"\"\"\n",
        "<style>\n",
        "    .main { background-color: #0E1117; color: #FAFAFA; }\n",
        "    div[data-testid=\"stTabs\"] { background-color: #161B22; border: 1px solid #30363D; }\n",
        "    h1, h2, h3, h4, h5, h6 { color: #C9D1D9; }\n",
        "</style>\n",
        "\"\"\"\n",
        "st.markdown(custom_css, unsafe_allow_html=True)\n",
        "\n",
        "# =============================================================================\n",
        "#  DATABASE & AUTHENTICATION BACKEND\n",
        "# =============================================================================\n",
        "\n",
        "def init_db():\n",
        "    conn = sqlite3.connect('llm_users.db')\n",
        "    c = conn.cursor()\n",
        "    c.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS users (\n",
        "            email TEXT PRIMARY KEY,\n",
        "            password_hash BLOB NOT NULL,\n",
        "            role TEXT NOT NULL\n",
        "        )\n",
        "    ''')\n",
        "    c.execute(\"SELECT * FROM users WHERE email='admin@gmail.com'\")\n",
        "    if c.fetchone() is None:\n",
        "        admin_email = \"admin@gmail.com\"\n",
        "        admin_pass = \"Milestone3\"\n",
        "        hashed_pass = bcrypt.hashpw(admin_pass.encode(), bcrypt.gensalt())\n",
        "        c.execute(\"INSERT INTO users (email, password_hash, role) VALUES (?, ?, ?)\", (admin_email, hashed_pass, \"Admin\"))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def get_all_users():\n",
        "    conn = sqlite3.connect('llm_users.db')\n",
        "    df = pd.read_sql_query(\"SELECT email, role FROM users\", conn)\n",
        "    conn.close()\n",
        "    return df\n",
        "\n",
        "def delete_user(email):\n",
        "    conn = sqlite3.connect('llm_users.db')\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"DELETE FROM users WHERE email=?\", (email,))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def verify_password(plain_password, hashed_password):\n",
        "    return bcrypt.checkpw(plain_password.encode('utf-8'), hashed_password)\n",
        "\n",
        "def register_user(email, password, role=\"General User\"):\n",
        "    conn = sqlite3.connect('llm_users.db')\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"SELECT * FROM users WHERE email=?\", (email,))\n",
        "    if c.fetchone(): conn.close(); return \"Email already exists.\"\n",
        "    hashed_password = bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt())\n",
        "    c.execute(\"INSERT INTO users (email, password_hash, role) VALUES (?, ?, ?)\", (email, hashed_password, role))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    return \"User registered successfully! Please log in.\"\n",
        "\n",
        "def generate_token(email, role):\n",
        "    payload = {'exp': datetime.utcnow() + timedelta(hours=1), 'iat': datetime.utcnow(), 'sub': email, 'role': role}\n",
        "    return jwt.encode(payload, SECRET_KEY, algorithm='HS256')\n",
        "\n",
        "def decode_token(token):\n",
        "    try: return jwt.decode(token, SECRET_KEY, algorithms=['HS256'])\n",
        "    except: return None\n",
        "\n",
        "def authenticate_user(email, password):\n",
        "    conn = sqlite3.connect('llm_users.db')\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"SELECT password_hash, role FROM users WHERE email=?\", (email,))\n",
        "    result = c.fetchone()\n",
        "    conn.close()\n",
        "    if result:\n",
        "        hashed_password_from_db, role = result\n",
        "        if verify_password(password, hashed_password_from_db):\n",
        "            return generate_token(email, role)\n",
        "    return None\n",
        "\n",
        "def reset_password(email, new_password):\n",
        "    \"\"\"Reset user password\"\"\"\n",
        "    conn = sqlite3.connect('llm_users.db')\n",
        "    c = conn.cursor()\n",
        "    hashed_password = bcrypt.hashpw(new_password.encode('utf-8'), bcrypt.gensalt())\n",
        "    c.execute(\"UPDATE users SET password_hash = ? WHERE email = ?\", (hashed_password, email))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    return True\n",
        "\n",
        "def user_exists(email):\n",
        "    \"\"\"Check if user exists in database\"\"\"\n",
        "    conn = sqlite3.connect('llm_users.db')\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"SELECT email FROM users WHERE email=?\", (email,))\n",
        "    result = c.fetchone()\n",
        "    conn.close()\n",
        "    return result is not None\n",
        "\n",
        "# =============================================================================\n",
        "#  FORGOT PASSWORD FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "def send_otp_email(email, otp):\n",
        "    \"\"\"Send OTP to user's email\"\"\"\n",
        "    try:\n",
        "        # Create message\n",
        "        message = MIMEMultipart()\n",
        "        message['From'] = EMAIL_CONFIG['sender_email']\n",
        "        message['To'] = email\n",
        "        message['Subject'] = 'Password Reset OTP - LLM AI Platform'\n",
        "\n",
        "        body = f\"\"\"\n",
        "        <html>\n",
        "            <body>\n",
        "                <h2>Password Reset Request</h2>\n",
        "                <p>Your One-Time Password (OTP) for password reset is:</p>\n",
        "                <h1 style=\"color: #0d6efd; font-size: 32px; text-align: center;\">{otp}</h1>\n",
        "                <p>This OTP is valid for 10 minutes.</p>\n",
        "                <p>If you didn't request this reset, please ignore this email.</p>\n",
        "                <br>\n",
        "                <p>Best regards,<br>LLM AI Platform Team</p>\n",
        "            </body>\n",
        "        </html>\n",
        "        \"\"\"\n",
        "\n",
        "        message.attach(MIMEText(body, 'html'))\n",
        "\n",
        "        # Connect to server and send email\n",
        "        server = smtplib.SMTP(EMAIL_CONFIG['smtp_server'], EMAIL_CONFIG['smtp_port'])\n",
        "        server.starttls()\n",
        "        server.login(EMAIL_CONFIG['sender_email'], EMAIL_CONFIG['sender_password'])\n",
        "        server.send_message(message)\n",
        "        server.quit()\n",
        "\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to send OTP email: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def generate_otp():\n",
        "    \"\"\"Generate a 6-digit OTP\"\"\"\n",
        "    return str(random.randint(100000, 999999))\n",
        "\n",
        "def forgot_password_flow():\n",
        "    \"\"\"Handle the forgot password flow with OTP\"\"\"\n",
        "    st.subheader(\"üîí Forgot Password\")\n",
        "\n",
        "    with st.form(\"forgot_password_form\"):\n",
        "        email = st.text_input(\"Enter your email address\", placeholder=\"your@email.com\")\n",
        "        submit = st.form_submit_button(\"Send OTP\")\n",
        "\n",
        "        if submit:\n",
        "            if user_exists(email):\n",
        "                # Generate and store OTP\n",
        "                otp = generate_otp()\n",
        "                st.session_state.otp_code = otp\n",
        "                st.session_state.otp_email = email\n",
        "                st.session_state.otp_expiry = datetime.now() + timedelta(minutes=10)\n",
        "\n",
        "                # Send OTP via email\n",
        "                if send_otp_email(email, otp):\n",
        "                    st.success(\"‚úÖ OTP sent to your email! Check your inbox.\")\n",
        "                    st.session_state.forgot_password_stage = \"verify_otp\"\n",
        "                    st.rerun()\n",
        "                else:\n",
        "                    st.error(\"‚ùå Failed to send OTP. Please try again.\")\n",
        "            else:\n",
        "                st.error(\"‚ùå Email not found in our system.\")\n",
        "\n",
        "    # OTP verification stage\n",
        "    if st.session_state.get('forgot_password_stage') == \"verify_otp\":\n",
        "        st.markdown(\"---\")\n",
        "        st.subheader(\"üìß Verify OTP\")\n",
        "\n",
        "        with st.form(\"verify_otp_form\"):\n",
        "            entered_otp = st.text_input(\"Enter 6-digit OTP\", placeholder=\"123456\")\n",
        "            new_password = st.text_input(\"New Password\", type=\"password\")\n",
        "            confirm_password = st.text_input(\"Confirm New Password\", type=\"password\")\n",
        "            submit_otp = st.form_submit_button(\"Reset Password\")\n",
        "\n",
        "            if submit_otp:\n",
        "                if datetime.now() > st.session_state.otp_expiry:\n",
        "                    st.error(\"‚ùå OTP has expired. Please request a new one.\")\n",
        "                    st.session_state.forgot_password_stage = \"request\"\n",
        "                    st.rerun()\n",
        "                elif entered_otp == st.session_state.otp_code:\n",
        "                    if new_password == confirm_password:\n",
        "                        if reset_password(st.session_state.otp_email, new_password):\n",
        "                            st.success(\"‚úÖ Password reset successfully! You can now login with your new password.\")\n",
        "                            # Clear OTP data\n",
        "                            if 'otp_code' in st.session_state:\n",
        "                                del st.session_state.otp_code\n",
        "                            if 'otp_email' in st.session_state:\n",
        "                                del st.session_state.otp_email\n",
        "                            if 'otp_expiry' in st.session_state:\n",
        "                                del st.session_state.otp_expiry\n",
        "                            st.session_state.forgot_password_stage = \"request\"\n",
        "                            st.rerun()\n",
        "                        else:\n",
        "                            st.error(\"‚ùå Failed to reset password. Please try again.\")\n",
        "                    else:\n",
        "                        st.error(\"‚ùå Passwords do not match.\")\n",
        "                else:\n",
        "                    st.error(\"‚ùå Invalid OTP. Please try again.\")\n",
        "\n",
        "init_db()\n",
        "\n",
        "# =============================================================================\n",
        "#  READABILITY ANALYSIS FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "def calculate_flesch_kincaid(text):\n",
        "    \"\"\"Calculate Flesch-Kincaid Grade Level\"\"\"\n",
        "    try:\n",
        "        sentences = simple_sent_tokenize(text)\n",
        "        words = simple_word_tokenize(text)\n",
        "        num_sentences = len(sentences)\n",
        "        num_words = len(words)\n",
        "\n",
        "        if num_sentences == 0 or num_words == 0:\n",
        "            return 0\n",
        "\n",
        "        # Count syllables\n",
        "        num_syllables = sum([count_syllables(word) for word in words])\n",
        "\n",
        "        # Flesch-Kincaid Grade Level formula\n",
        "        fk_grade = 0.39 * (num_words / num_sentences) + 11.8 * (num_syllables / num_words) - 15.59\n",
        "        return max(0, round(fk_grade, 1))\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error in Flesch-Kincaid calculation: {e}\")\n",
        "        return 0\n",
        "\n",
        "def calculate_gunning_fog(text):\n",
        "    \"\"\"Calculate Gunning Fog Index\"\"\"\n",
        "    try:\n",
        "        sentences = simple_sent_tokenize(text)\n",
        "        words = simple_word_tokenize(text)\n",
        "        num_sentences = len(sentences)\n",
        "        num_words = len(words)\n",
        "\n",
        "        if num_sentences == 0 or num_words == 0:\n",
        "            return 0\n",
        "\n",
        "        # Count complex words (words with 3 or more syllables)\n",
        "        complex_words = 0\n",
        "        for word in words:\n",
        "            if count_syllables(word) >= 3:\n",
        "                complex_words += 1\n",
        "\n",
        "        # Gunning Fog formula\n",
        "        fog_index = 0.4 * ((num_words / num_sentences) + 100 * (complex_words / num_words))\n",
        "        return max(0, round(fog_index, 1))\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error in Gunning Fog calculation: {e}\")\n",
        "        return 0\n",
        "\n",
        "def calculate_smog(text):\n",
        "    \"\"\"Calculate SMOG Index\"\"\"\n",
        "    try:\n",
        "        sentences = simple_sent_tokenize(text)\n",
        "        if len(sentences) < 3:\n",
        "            return 0\n",
        "\n",
        "        # Count polysyllable words (3+ syllables)\n",
        "        polysyllable_count = 0\n",
        "        for sentence in sentences:\n",
        "            words = simple_word_tokenize(sentence)\n",
        "            for word in words:\n",
        "                if count_syllables(word) >= 3:\n",
        "                    polysyllable_count += 1\n",
        "\n",
        "        # SMOG formula (simplified)\n",
        "        smog_index = 1.043 * (polysyllable_count ** 0.5) + 3.1291\n",
        "        return max(0, round(smog_index, 1))\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error in SMOG calculation: {e}\")\n",
        "        return 0\n",
        "\n",
        "def count_syllables(word):\n",
        "    \"\"\"Approximate syllable count for a word\"\"\"\n",
        "    try:\n",
        "        word = word.lower()\n",
        "        if len(word) <= 3:\n",
        "            return 1\n",
        "\n",
        "        count = 0\n",
        "        vowels = \"aeiouy\"\n",
        "\n",
        "        if word[0] in vowels:\n",
        "            count += 1\n",
        "\n",
        "        for index in range(1, len(word)):\n",
        "            if word[index] in vowels and word[index-1] not in vowels:\n",
        "                count += 1\n",
        "\n",
        "        if word.endswith(\"e\"):\n",
        "            count -= 1\n",
        "\n",
        "        if word.endswith(\"le\") and len(word) > 2 and word[-3] not in vowels:\n",
        "            count += 1\n",
        "\n",
        "        if count == 0:\n",
        "            count += 1\n",
        "\n",
        "        return max(1, count)\n",
        "    except:\n",
        "        return 1\n",
        "\n",
        "def create_readability_gauge(fk_score, fog_score, smog_score):\n",
        "    \"\"\"Create a vertical bar chart showing all three scores with their levels\"\"\"\n",
        "    try:\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "        # Define the levels\n",
        "        levels = ['Beginner', 'Intermediate', 'Advanced']\n",
        "\n",
        "        # Assign each score to a level based on value (ascending order)\n",
        "        scores_sorted = sorted([fk_score, fog_score, smog_score])\n",
        "\n",
        "        # Create values array - assign lowest to Beginner, middle to Intermediate, highest to Advanced\n",
        "        values = [scores_sorted[0], scores_sorted[1], scores_sorted[2]]\n",
        "\n",
        "        # Define colors for each metric\n",
        "        colors = ['#28a745', '#ffc107', '#dc3545']  # Green, Yellow, Red\n",
        "\n",
        "        # Create the bar chart\n",
        "        bars = ax.bar(levels, values, color=colors, alpha=0.8)\n",
        "\n",
        "        # Customize the chart\n",
        "        ax.set_ylabel('Readability Score', fontweight='bold', fontsize=12)\n",
        "        ax.set_ylim(0, max(values) + 10)  # Dynamic y-axis limit\n",
        "        ax.set_xlabel('Difficulty Level', fontweight='bold', fontsize=12)\n",
        "\n",
        "        # Remove top and right spines\n",
        "        ax.spines['top'].set_visible(False)\n",
        "        ax.spines['right'].set_visible(False)\n",
        "\n",
        "        # Add grid lines\n",
        "        ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "        # Add value labels on top of each bar\n",
        "        for bar, value in zip(bars, values):\n",
        "            height = bar.get_height()\n",
        "            ax.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
        "                   f'{value}', ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
        "\n",
        "        # Add legend to show which color represents which metric\n",
        "        from matplotlib.patches import Patch\n",
        "        legend_elements = [\n",
        "            Patch(facecolor='#28a745', label=f'Flesch-Kincaid: {fk_score}'),\n",
        "            Patch(facecolor='#ffc107', label=f'Gunning Fog: {fog_score}'),\n",
        "            Patch(facecolor='#dc3545', label=f'SMOG Index: {smog_score}')\n",
        "        ]\n",
        "        ax.legend(handles=legend_elements, loc='upper right')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error creating chart: {e}\")\n",
        "        return None\n",
        "\n",
        "# =============================================================================\n",
        "#  PDF EXTRACTION FUNCTION\n",
        "# =============================================================================\n",
        "\n",
        "def extract_text_from_pdf(uploaded_file):\n",
        "    \"\"\"Extract text from PDF using available libraries\"\"\"\n",
        "    try:\n",
        "        # Try PyPDF2 first\n",
        "        try:\n",
        "            import PyPDF2\n",
        "            uploaded_file.seek(0)  # Reset file pointer\n",
        "            pdf_reader = PyPDF2.PdfReader(uploaded_file)\n",
        "            text = \"\"\n",
        "            for page in pdf_reader.pages:\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "            return text, len(pdf_reader.pages), \"PyPDF2\"\n",
        "        except ImportError:\n",
        "            pass\n",
        "\n",
        "        # Try pypdf (newer version)\n",
        "        try:\n",
        "            import pypdf\n",
        "            uploaded_file.seek(0)  # Reset file pointer\n",
        "            pdf_reader = pypdf.PdfReader(uploaded_file)\n",
        "            text = \"\"\n",
        "            for page in pdf_reader.pages:\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "            return text, len(pdf_reader.pages), \"pypdf\"\n",
        "        except ImportError:\n",
        "            pass\n",
        "\n",
        "        # If neither library is available\n",
        "        return None, 0, \"none\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, 0, f\"error: {str(e)}\"\n",
        "\n",
        "# =============================================================================\n",
        "#  UI SECTION: READABILITY DASHBOARD FOR GENERAL USERS\n",
        "# =============================================================================\n",
        "\n",
        "def readability_dashboard():\n",
        "    st.title(\"üìä Dashboard & Readability Analysis\")\n",
        "\n",
        "    # File upload section\n",
        "    st.header(\"Upload Document\")\n",
        "\n",
        "    # File uploader for multiple file types\n",
        "    uploaded_file = st.file_uploader(\n",
        "        \"Drag and drop file here\\n\\nLimit 200MB per file ‚Ä¢ TXT, PDF, CSV\",\n",
        "        type=[\"txt\", \"pdf\", \"csv\"],\n",
        "        help=\"Upload a text, PDF, or CSV file for analysis\",\n",
        "        label_visibility=\"visible\"\n",
        "    )\n",
        "\n",
        "    text_to_analyze = \"\"\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        # Display file name only (no additional boxes)\n",
        "        file_name = uploaded_file.name\n",
        "        file_size = len(uploaded_file.getvalue()) / 1024  # Size in KB\n",
        "\n",
        "        # Simple file name display\n",
        "        st.write(f\"**{file_name}**  {file_size:.2f}KB\")\n",
        "\n",
        "        # Handle text files\n",
        "        if uploaded_file.type == \"text/plain\":\n",
        "            try:\n",
        "                text_to_analyze = uploaded_file.read().decode(\"utf-8\")\n",
        "                st.success(f\"‚úÖ Text file uploaded successfully! ({len(text_to_analyze)} characters)\")\n",
        "            except Exception as e:\n",
        "                st.error(f\"Error reading text file: {e}\")\n",
        "\n",
        "        # Handle CSV files\n",
        "        elif uploaded_file.type == \"text/csv\" or uploaded_file.name.endswith('.csv'):\n",
        "            try:\n",
        "                df = pd.read_csv(uploaded_file)\n",
        "                # Convert dataframe to text for analysis\n",
        "                text_to_analyze = df.to_string()\n",
        "                st.success(f\"‚úÖ CSV file uploaded successfully! ({len(df)} rows)\")\n",
        "                st.dataframe(df.head())  # Show preview\n",
        "            except Exception as e:\n",
        "                st.error(f\"Error reading CSV file: {e}\")\n",
        "\n",
        "        # Handle PDF files - IMPROVED VERSION\n",
        "        elif uploaded_file.type == \"application/pdf\":\n",
        "            try:\n",
        "                # Extract text from PDF\n",
        "                extracted_text, page_count, library_used = extract_text_from_pdf(uploaded_file)\n",
        "\n",
        "                if extracted_text is not None:\n",
        "                    text_to_analyze = extracted_text\n",
        "                    if text_to_analyze.strip():\n",
        "                        st.success(f\"‚úÖ PDF file processed successfully! ({page_count} pages, using {library_used})\")\n",
        "                        st.info(f\"Extracted {len(text_to_analyze)} characters from PDF\")\n",
        "                    else:\n",
        "                        st.warning(\"PDF was processed but no text content was extracted. This might be a scanned PDF or image-based PDF.\")\n",
        "                else:\n",
        "                    if library_used == \"none\":\n",
        "                        st.error(\"PDF extraction requires either PyPDF2 or pypdf package.\")\n",
        "                        st.code(\"pip install pypdf\", language=\"bash\")\n",
        "                        st.info(\"Please install pypdf using the command above and restart the application.\")\n",
        "                    else:\n",
        "                        st.error(f\"Failed to extract text from PDF: {library_used}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                st.error(f\"Error processing PDF file: {e}\")\n",
        "                st.info(\"If PDF extraction fails, please upload a text file instead.\")\n",
        "\n",
        "        else:\n",
        "            st.warning(f\"Unsupported file type: {uploaded_file.type}\")\n",
        "\n",
        "    # Text input area\n",
        "    st.subheader(\"Or enter text manually:\")\n",
        "    user_text = st.text_area(\n",
        "        \"Paste your text here for analysis\",\n",
        "        height=150,\n",
        "        placeholder=\"Enter the text you want to analyze for readability...\",\n",
        "        label_visibility=\"collapsed\"\n",
        "    )\n",
        "\n",
        "    # Use manual text if no file uploaded\n",
        "    if user_text and not text_to_analyze:\n",
        "        text_to_analyze = user_text\n",
        "\n",
        "    # Analysis button\n",
        "    analyze_clicked = st.button(\"Analyze Readability\", type=\"primary\", use_container_width=True)\n",
        "\n",
        "    # Perform analysis when button is clicked and we have text\n",
        "    if analyze_clicked and text_to_analyze:\n",
        "        if len(text_to_analyze.strip()) < 50:\n",
        "            st.warning(\"Please enter at least 50 characters for accurate analysis.\")\n",
        "        else:\n",
        "            with st.spinner(\"Analyzing text readability...\"):\n",
        "                # Calculate readability scores\n",
        "                fk_score = calculate_flesch_kincaid(text_to_analyze)\n",
        "                fog_score = calculate_gunning_fog(text_to_analyze)\n",
        "                smog_score = calculate_smog(text_to_analyze)\n",
        "\n",
        "                # Display metrics in columns\n",
        "                st.markdown(\"---\")\n",
        "                st.header(\"Readability Scores\")\n",
        "\n",
        "                col1, col2, col3 = st.columns(3)\n",
        "\n",
        "                with col1:\n",
        "                    st.markdown(f\"\"\"\n",
        "                    <div class=\"metric-card\">\n",
        "                        <div class=\"metric-value\">{fk_score}</div>\n",
        "                        <div class=\"metric-label\">Flesch-Kincaid</div>\n",
        "                    </div>\n",
        "                    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                with col2:\n",
        "                    st.markdown(f\"\"\"\n",
        "                    <div class=\"metric-card\">\n",
        "                        <div class=\"metric-value\">{fog_score}</div>\n",
        "                        <div class=\"metric-label\">Gunning Fog</div>\n",
        "                    </div>\n",
        "                    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                with col3:\n",
        "                    st.markdown(f\"\"\"\n",
        "                    <div class=\"metric-card\">\n",
        "                        <div class=\"metric-value\">{smog_score}</div>\n",
        "                        <div class=\"metric-label\">SMOG Index</div>\n",
        "                    </div>\n",
        "                    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                # Display the gauge chart\n",
        "                st.markdown(\"---\")\n",
        "                st.header(\"Readability Visualization\")\n",
        "\n",
        "                gauge_chart = create_readability_gauge(fk_score, fog_score, smog_score)\n",
        "                if gauge_chart:\n",
        "                    st.pyplot(gauge_chart)\n",
        "\n",
        "                # Interpretation\n",
        "                st.markdown(\"---\")\n",
        "                st.header(\"Interpretation\")\n",
        "\n",
        "                # Determine overall level based on average score\n",
        "                avg_score = (fk_score + fog_score + smog_score) / 3\n",
        "                if avg_score <= 8:\n",
        "                    st.success(\"**Overall Level: Beginner** - This text is easy to read and suitable for general audiences.\")\n",
        "                elif avg_score <= 12:\n",
        "                    st.warning(\"**Overall Level: Intermediate** - This text requires some reading proficiency.\")\n",
        "                else:\n",
        "                    st.error(\"**Overall Level: Advanced** - This text is complex and may be challenging to read.\")\n",
        "\n",
        "                # Show individual score details\n",
        "                with st.expander(\"View Detailed Scores\"):\n",
        "                    st.write(f\"**Flesch-Kincaid:** {fk_score} (Grade level)\")\n",
        "                    st.write(f\"**Gunning Fog:** {fog_score} (Years of education needed)\")\n",
        "                    st.write(f\"**SMOG Index:** {smog_score} (Years of education needed)\")\n",
        "\n",
        "    elif analyze_clicked and not text_to_analyze:\n",
        "        st.warning(\"Please upload a file or enter text to analyze.\")\n",
        "\n",
        "    # Analysis Features section (always visible)\n",
        "    st.markdown(\"---\")\n",
        "    st.header(\"Analysis Features\")\n",
        "\n",
        "    feature_col1, feature_col2, feature_col3 = st.columns(3)\n",
        "\n",
        "    with feature_col1:\n",
        "        st.markdown(\"\"\"\n",
        "        **üìä Real-time readability scoring**\n",
        "        Instant calculation of multiple readability metrics\n",
        "        \"\"\")\n",
        "\n",
        "    with feature_col2:\n",
        "        st.markdown(\"\"\"\n",
        "        **üé® Visual complexity indicators**\n",
        "        Color-coded charts showing text difficulty levels\n",
        "        \"\"\")\n",
        "\n",
        "    with feature_col3:\n",
        "        st.markdown(\"\"\"\n",
        "        **üìà Comprehensive test metrics**\n",
        "        Multiple algorithms for accurate assessment\n",
        "        \"\"\")\n",
        "\n",
        "# =============================================================================\n",
        "#  UI SECTION: MULTI-LEVEL SUMMARIZATION (UPDATED WITH LOCAL MODELS)\n",
        "# =============================================================================\n",
        "def multi_level_summarization():\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    from datetime import datetime\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # Initialize session state for history\n",
        "    if 'summarization_history' not in st.session_state:\n",
        "        st.session_state.summarization_history = []\n",
        "\n",
        "    # Show ready status\n",
        "    st.success(\"‚úÖ AI Summarization Ready! Using Local Models\")\n",
        "\n",
        "    def extract_text_from_pdf_summary(uploaded_file):\n",
        "        try:\n",
        "            # Try PyPDF2 first\n",
        "            try:\n",
        "                import PyPDF2\n",
        "                pdf_reader = PyPDF2.PdfReader(uploaded_file)\n",
        "                text = \"\"\n",
        "                for page in pdf_reader.pages:\n",
        "                    text += page.extract_text() + \"\\n\"\n",
        "                return text, len(pdf_reader.pages), \"PyPDF2\"\n",
        "            except ImportError:\n",
        "                pass\n",
        "\n",
        "            # Try pypdf\n",
        "            try:\n",
        "                import pypdf\n",
        "                pdf_reader = pypdf.PdfReader(uploaded_file)\n",
        "                text = \"\"\n",
        "                for page in pdf_reader.pages:\n",
        "                    text += page.extract_text() + \"\\n\"\n",
        "                return text, len(pdf_reader.pages), \"pypdf\"\n",
        "            except ImportError:\n",
        "                pass\n",
        "\n",
        "            return None, 0, \"none\"\n",
        "        except Exception as e:\n",
        "            return None, 0, f\"error: {str(e)}\"\n",
        "\n",
        "    def simple_sent_tokenize_summary(text):\n",
        "        \"\"\"Simple sentence tokenizer as fallback\"\"\"\n",
        "        try:\n",
        "            return sent_tokenize(text)\n",
        "        except:\n",
        "            # Fallback: split on common sentence endings\n",
        "            sentences = re.split(r'[.!?]+', text)\n",
        "            return [s.strip() for s in sentences if s.strip()]\n",
        "\n",
        "    def calculate_rouge(original, summary):\n",
        "        \"\"\"Simple ROUGE-like scoring for demonstration\"\"\"\n",
        "        if \"error\" in summary.lower() or \"failed\" in summary.lower():\n",
        "            return {\"rouge1\": 0.3, \"rouge2\": 0.2, \"rougeL\": 0.25}\n",
        "\n",
        "        original_words = set(original.lower().split())\n",
        "        summary_words = set(summary.lower().split())\n",
        "\n",
        "        common_words = original_words.intersection(summary_words)\n",
        "\n",
        "        if len(original_words) == 0:\n",
        "            return {\"rouge1\": 0.0, \"rouge2\": 0.0, \"rougeL\": 0.0}\n",
        "\n",
        "        rouge1 = len(common_words) / len(original_words)\n",
        "        rouge2 = rouge1 * 0.8\n",
        "        rougeL = rouge1 * 0.9\n",
        "\n",
        "        return {\n",
        "            \"rouge1\": min(rouge1, 0.95),\n",
        "            \"rouge2\": min(rouge2, 0.85),\n",
        "            \"rougeL\": min(rougeL, 0.90)\n",
        "        }\n",
        "\n",
        "    def calculate_metrics(original_text, summary_text):\n",
        "        \"\"\"Calculate basic text metrics\"\"\"\n",
        "        original_words = len(original_text.split())\n",
        "        summary_words = len(summary_text.split())\n",
        "        compression_ratio = (original_words - summary_words) / original_words * 100 if original_words > 0 else 0\n",
        "\n",
        "        return {\n",
        "            'original_words': original_words,\n",
        "            'summary_words': summary_words,\n",
        "            'compression_ratio': round(compression_ratio, 1)\n",
        "        }\n",
        "\n",
        "    def create_rouge_l_chart(rouge_scores):\n",
        "        \"\"\"Create a bar chart for ROUGE metrics\"\"\"\n",
        "        try:\n",
        "            fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "            metrics = ['ROUGE-1', 'ROUGE-2', 'ROUGE-L']\n",
        "            scores = [\n",
        "                rouge_scores['rouge1'] * 100,\n",
        "                rouge_scores['rouge2'] * 100,\n",
        "                rouge_scores['rougeL'] * 100\n",
        "            ]\n",
        "\n",
        "            colors = ['#4CAF50', '#2196F3', '#FF9800']\n",
        "            bars = ax.bar(metrics, scores, color=colors, alpha=0.8, width=0.6)\n",
        "\n",
        "            ax.set_ylabel('Score (%)', fontweight='bold', fontsize=12)\n",
        "            ax.set_ylim(0, 100)\n",
        "            ax.set_title('ROUGE Metrics Evaluation', fontweight='bold', fontsize=14, pad=20)\n",
        "\n",
        "            ax.spines['top'].set_visible(False)\n",
        "            ax.spines['right'].set_visible(False)\n",
        "            ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "            for bar, score in zip(bars, scores):\n",
        "                height = bar.get_height()\n",
        "                ax.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
        "                       f'{score:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
        "\n",
        "            ax.axhline(y=50, color='red', linestyle='--', alpha=0.3, label='Good (50%)')\n",
        "            ax.axhline(y=70, color='green', linestyle='--', alpha=0.3, label='Excellent (70%)')\n",
        "            ax.legend(loc='upper right')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            return fig\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error creating chart: {e}\")\n",
        "            return None\n",
        "\n",
        "    def add_to_history(original_text, summary_text, summary_length, model_type, rouge_scores):\n",
        "        \"\"\"Add current summarization to history\"\"\"\n",
        "        metrics = calculate_metrics(original_text, summary_text)\n",
        "\n",
        "        history_entry = {\n",
        "            'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            'original_text': original_text[:100] + \"...\" if len(original_text) > 100 else original_text,\n",
        "            'summary_text': summary_text,\n",
        "            'summary_length': summary_length,\n",
        "            'model_type': model_type,\n",
        "            'original_words': metrics['original_words'],\n",
        "            'summary_words': metrics['summary_words'],\n",
        "            'compression_ratio': metrics['compression_ratio'],\n",
        "            'rouge1': round(rouge_scores['rouge1'] * 100, 2),\n",
        "            'rouge2': round(rouge_scores['rouge2'] * 100, 2),\n",
        "            'rougeL': round(rouge_scores['rougeL'] * 100, 2)\n",
        "        }\n",
        "        st.session_state.summarization_history.insert(0, history_entry)\n",
        "\n",
        "        # Keep only last 10 entries\n",
        "        if len(st.session_state.summarization_history) > 10:\n",
        "            st.session_state.summarization_history = st.session_state.summarization_history[:10]\n",
        "\n",
        "    # Main UI for summarization\n",
        "    st.title(\"üìù Multi-level Summarization\")\n",
        "\n",
        "    # Main tabs\n",
        "    tab1, tab2 = st.tabs([\"Summarization\", \"History\"])\n",
        "\n",
        "    with tab1:\n",
        "        col1, col2 = st.columns([2, 1])\n",
        "\n",
        "        with col1:\n",
        "            st.subheader(\"Import Text\")\n",
        "\n",
        "            text_source = st.radio(\"Choose text source:\", [\"Enter Text\", \"Upload File\"], horizontal=True)\n",
        "\n",
        "            if text_source == \"Enter Text\":\n",
        "                input_text = st.text_area(\n",
        "                    \"Paste your text here:\",\n",
        "                    height=200,\n",
        "                    placeholder=\"Enter or paste the text you want to summarize...\",\n",
        "                    key=\"summarization_text_input\"\n",
        "                )\n",
        "            else:\n",
        "                uploaded_file = st.file_uploader(\"Upload text file\", type=['txt', 'pdf'])\n",
        "\n",
        "                if uploaded_file is not None:\n",
        "                    file_name = uploaded_file.name\n",
        "                    file_size = len(uploaded_file.getvalue()) / 1024\n",
        "                    st.write(f\"**{file_name}**  {file_size:.2f}KB\")\n",
        "\n",
        "                    if uploaded_file.type == \"text/plain\":\n",
        "                        input_text = uploaded_file.read().decode(\"utf-8\")\n",
        "                        st.success(\"Text file loaded successfully!\")\n",
        "                    elif uploaded_file.type == \"application/pdf\":\n",
        "                        extracted_text, page_count, library_used = extract_text_from_pdf_summary(uploaded_file)\n",
        "                        if extracted_text:\n",
        "                            input_text = extracted_text\n",
        "                            st.success(f\"PDF processed successfully! ({page_count} pages)\")\n",
        "                        else:\n",
        "                            st.error(\"Failed to extract text from PDF\")\n",
        "                            input_text = \"\"\n",
        "                    else:\n",
        "                        st.warning(\"Unsupported file type\")\n",
        "                        input_text = \"\"\n",
        "                else:\n",
        "                    input_text = \"\"\n",
        "\n",
        "            if input_text:\n",
        "                with st.expander(\"Text Preview\"):\n",
        "                    st.text_area(\"Preview\", input_text[:500] + \"...\" if len(input_text) > 500 else input_text, height=100, key=\"preview\", label_visibility=\"collapsed\")\n",
        "\n",
        "        with col2:\n",
        "            st.subheader(\"Summary Configuration\")\n",
        "\n",
        "            st.write(\"**Summary Length**\")\n",
        "            summary_length = st.radio(\n",
        "                \"Length\",\n",
        "                [\"Short\", \"Medium\", \"Long\"],\n",
        "                index=1,\n",
        "                label_visibility=\"collapsed\"\n",
        "            )\n",
        "\n",
        "            st.markdown(\"---\")\n",
        "\n",
        "            st.write(\"**Model Selection**\")\n",
        "            available_models = [\"BART\", \"Pegasus\", \"FLAN-T5\"]\n",
        "            model_selection = st.selectbox(\n",
        "                \"Choose model:\",\n",
        "                available_models,\n",
        "                index=0,\n",
        "                label_visibility=\"collapsed\"\n",
        "            )\n",
        "\n",
        "            st.markdown(\"---\")\n",
        "\n",
        "            generate_clicked = st.button(\n",
        "                \"Generate Summary\",\n",
        "                type=\"primary\",\n",
        "                use_container_width=True,\n",
        "                disabled=not input_text.strip()\n",
        "            )\n",
        "\n",
        "        if generate_clicked and input_text.strip():\n",
        "            # Load the selected model\n",
        "            summarizer = load_summarization_model(model_selection)\n",
        "\n",
        "            if summarizer is None:\n",
        "                st.error(f\"‚ùå Failed to load {model_selection} model. Please try again.\")\n",
        "            else:\n",
        "                with st.spinner(f\"üöÄ Generating {summary_length.lower()} summary using {model_selection}...\"):\n",
        "                    start_time = time.time()\n",
        "                    # Use local model instead of API\n",
        "                    summary_text = local_summarize(summarizer, input_text, summary_length)\n",
        "                    end_time = time.time()\n",
        "\n",
        "                    metrics = calculate_metrics(input_text, summary_text)\n",
        "                    rouge_scores = calculate_rouge(input_text, summary_text)\n",
        "                    add_to_history(input_text, summary_text, summary_length, model_selection, rouge_scores)\n",
        "\n",
        "                    st.markdown(\"---\")\n",
        "                    st.subheader(\"üìã Summary Results\")\n",
        "\n",
        "                    col1, col2 = st.columns(2)\n",
        "\n",
        "                    with col1:\n",
        "                        st.markdown(\"**Original Text**\")\n",
        "                        st.markdown(f\"**{metrics['original_words']} words**\")\n",
        "                        st.info(input_text[:800] + \"...\" if len(input_text) > 800 else input_text)\n",
        "\n",
        "                    with col2:\n",
        "                        st.markdown(\"**Generated Summary**\")\n",
        "                        st.markdown(f\"**{metrics['summary_words']} words**\")\n",
        "                        if \"error\" in summary_text.lower() or \"failed\" in summary_text.lower():\n",
        "                            st.error(summary_text)\n",
        "                        else:\n",
        "                            st.success(summary_text)\n",
        "\n",
        "                    st.markdown(\"---\")\n",
        "                    st.subheader(\"üìä Summary Metrics\")\n",
        "\n",
        "                    col1, col2, col3, col4 = st.columns(4)\n",
        "                    with col1:\n",
        "                        st.metric(\"Compression Ratio\", f\"{metrics['compression_ratio']}%\")\n",
        "                    with col2:\n",
        "                        st.metric(\"ROUGE-1\", f\"{rouge_scores['rouge1']*100:.1f}%\")\n",
        "                    with col3:\n",
        "                        st.metric(\"ROUGE-2\", f\"{rouge_scores['rouge2']*100:.1f}%\")\n",
        "                    with col4:\n",
        "                        st.metric(\"ROUGE-L\", f\"{rouge_scores['rougeL']*100:.1f}%\")\n",
        "\n",
        "                    # Show performance info\n",
        "                    st.info(f\"‚è±Ô∏è Generated in {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "                    # ROUGE-L Visualization\n",
        "                    st.markdown(\"---\")\n",
        "                    st.subheader(\"üìà ROUGE Metrics Visualization\")\n",
        "\n",
        "                    rouge_chart = create_rouge_l_chart(rouge_scores)\n",
        "                    if rouge_chart:\n",
        "                        st.pyplot(rouge_chart)\n",
        "\n",
        "                    # Interpretation of ROUGE scores\n",
        "                    with st.expander(\"üìñ Understanding ROUGE Scores\"):\n",
        "                        st.markdown(\"\"\"\n",
        "                        **ROUGE (Recall-Oriented Understudy for Gisting Evaluation) Metrics:**\n",
        "\n",
        "                        - **ROUGE-1**: Measures overlap of unigrams (single words) between summary and original\n",
        "                        - **ROUGE-2**: Measures overlap of bigrams (two-word sequences)\n",
        "                        - **ROUGE-L**: Measures longest common subsequence, capturing sentence structure\n",
        "\n",
        "                        **Interpretation Guide:**\n",
        "                        - **< 30%**: Poor summary quality\n",
        "                        - **30-50%**: Fair summary quality\n",
        "                        - **50-70%**: Good summary quality\n",
        "                        - **> 70%**: Excellent summary quality\n",
        "\n",
        "                        *Note: These scores are approximate and may vary based on text complexity.*\n",
        "                        \"\"\")\n",
        "\n",
        "        elif generate_clicked and not input_text.strip():\n",
        "            st.warning(\"Please enter some text or upload a file to summarize.\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.subheader(\"üîë Key Features\")\n",
        "\n",
        "        feature_col1, feature_col2, feature_col3 = st.columns(3)\n",
        "\n",
        "        with feature_col1:\n",
        "            st.markdown(\"\"\"\n",
        "            **ü§ñ Advanced NLP Models**\n",
        "            - Pegasus: Abstractive summarization\n",
        "            - FLAN-T5: Instruction-tuned model\n",
        "            - BART: Denoising autoencoder\n",
        "            \"\"\")\n",
        "\n",
        "        with feature_col2:\n",
        "            st.markdown(\"\"\"\n",
        "            **üìä Quality Evaluation**\n",
        "            - ROUGE metrics scoring\n",
        "            - Compression ratio analysis\n",
        "            - Side-by-side comparison\n",
        "            \"\"\")\n",
        "\n",
        "        with feature_col3:\n",
        "            st.markdown(\"\"\"\n",
        "            **üéØ Multi-level Output**\n",
        "            - Short summaries (key points)\n",
        "            - Medium summaries (balanced)\n",
        "            - Long summaries (detailed)\n",
        "            \"\"\")\n",
        "\n",
        "    with tab2:\n",
        "        st.subheader(\"üìú Summarization History\")\n",
        "\n",
        "        if st.session_state.summarization_history:\n",
        "            history_data = []\n",
        "            for entry in st.session_state.summarization_history:\n",
        "                history_data.append({\n",
        "                    'Timestamp': entry['timestamp'],\n",
        "                    'Model': entry['model_type'],\n",
        "                    'Length': entry['summary_length'],\n",
        "                    'Original Words': entry['original_words'],\n",
        "                    'Summary Words': entry['summary_words'],\n",
        "                    'Compression %': entry['compression_ratio'],\n",
        "                    'ROUGE-1': f\"{entry['rouge1']}%\",\n",
        "                    'ROUGE-2': f\"{entry['rouge2']}%\",\n",
        "                    'ROUGE-L': f\"{entry['rougeL']}%\"\n",
        "                })\n",
        "\n",
        "            history_df = pd.DataFrame(history_data)\n",
        "            st.dataframe(history_df, use_container_width=True)\n",
        "\n",
        "            # Add ROUGE-L trend visualization in history\n",
        "            if len(st.session_state.summarization_history) > 1:\n",
        "                st.markdown(\"---\")\n",
        "                st.subheader(\"üìà ROUGE-L Score Trend\")\n",
        "\n",
        "                # Prepare data for trend chart\n",
        "                history_dates = [entry['timestamp'] for entry in st.session_state.summarization_history]\n",
        "                rouge_l_scores = [entry['rougeL'] for entry in st.session_state.summarization_history]\n",
        "\n",
        "                fig, ax = plt.subplots(figsize=(10, 4))\n",
        "                ax.plot(history_dates[::-1], rouge_l_scores[::-1], marker='o', linewidth=2, markersize=6, color='#FF9800')\n",
        "                ax.set_ylabel('ROUGE-L Score (%)', fontweight='bold')\n",
        "                ax.set_xlabel('Summary Attempts', fontweight='bold')\n",
        "                ax.set_title('ROUGE-L Score Trend Over Time', fontweight='bold')\n",
        "                ax.grid(True, alpha=0.3)\n",
        "                plt.xticks(rotation=45)\n",
        "                plt.tight_layout()\n",
        "                st.pyplot(fig)\n",
        "\n",
        "            if st.button(\"Clear History\", type=\"secondary\"):\n",
        "                st.session_state.summarization_history = []\n",
        "                st.rerun()\n",
        "        else:\n",
        "            st.info(\"No summarization history yet. Generate some summaries to see them here!\")\n",
        "\n",
        "# =============================================================================\n",
        "#  UI SECTION: COMPLEXITY PARAPHRASING (UPDATED WITH LOCAL MODELS)\n",
        "# =============================================================================\n",
        "\n",
        "def complexity_paraphrasing():\n",
        "    import pandas as pd\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    from datetime import datetime\n",
        "\n",
        "    # Initialize session state for paraphrasing history\n",
        "    if 'paraphrasing_history' not in st.session_state:\n",
        "        st.session_state.paraphrasing_history = []\n",
        "\n",
        "    # Load local models\n",
        "    paraphrase_model, paraphrase_tokenizer = load_paraphrase_model()\n",
        "    if paraphrase_model is not None:\n",
        "        st.success(\"‚úÖ AI Paraphrasing Ready! Using Local FLAN-T5 Model\")\n",
        "    else:\n",
        "        st.error(\"‚ùå Paraphrase model failed to load. Please refresh the page.\")\n",
        "\n",
        "    st.title(\"üîÑ Complexity-based Paraphrasing\")\n",
        "\n",
        "    # Main layout\n",
        "    col1, col2 = st.columns([2, 1])\n",
        "\n",
        "    with col1:\n",
        "        st.subheader(\"Input Text\")\n",
        "\n",
        "        # Text input options\n",
        "        text_source = st.radio(\"Choose text source:\", [\"Enter Text\", \"Upload File\"], horizontal=True, key=\"para_source\")\n",
        "\n",
        "        if text_source == \"Enter Text\":\n",
        "            input_text = st.text_area(\n",
        "                \"Enter text to paraphrase:\",\n",
        "                height=200,\n",
        "                placeholder=\"Paste your text here for paraphrasing...\",\n",
        "                key=\"para_text_input\"\n",
        "            )\n",
        "        else:\n",
        "            uploaded_file = st.file_uploader(\"Upload text file\", type=['txt'], key=\"para_upload\")\n",
        "            if uploaded_file is not None:\n",
        "                input_text = uploaded_file.read().decode(\"utf-8\")\n",
        "                st.success(f\"‚úÖ File uploaded successfully! ({len(input_text)} characters)\")\n",
        "            else:\n",
        "                input_text = \"\"\n",
        "\n",
        "        if input_text:\n",
        "            with st.expander(\"Text Preview\"):\n",
        "                st.text_area(\"Preview\", input_text[:300] + \"...\" if len(input_text) > 300 else input_text,\n",
        "                           height=100, key=\"para_preview\", label_visibility=\"collapsed\")\n",
        "\n",
        "    with col2:\n",
        "        st.subheader(\"Paraphrasing Settings\")\n",
        "\n",
        "        # Model selection\n",
        "        st.write(\"**Model Selection**\")\n",
        "        model_type = st.selectbox(\n",
        "            \"Choose model:\",\n",
        "            [\"FLAN-T5\", \"BART\"],\n",
        "            index=0,\n",
        "            label_visibility=\"collapsed\"\n",
        "        )\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # Complexity level selection\n",
        "        st.write(\"**Complexity Level**\")\n",
        "        complexity_level = st.selectbox(\n",
        "            \"Target complexity:\",\n",
        "            [\"Beginner\", \"Intermediate\", \"Advanced\", \"Expert\"],\n",
        "            index=1,\n",
        "            label_visibility=\"collapsed\"\n",
        "        )\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # Paraphrasing style\n",
        "        st.write(\"**Paraphrasing Style**\")\n",
        "        paraphrasing_style = st.radio(\n",
        "            \"Style:\",\n",
        "            [\"Simplification\", \"Formalization\", \"Neutral\"],\n",
        "            index=0,\n",
        "            label_visibility=\"collapsed\"\n",
        "        )\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # Generate button\n",
        "        generate_clicked = st.button(\n",
        "            \"Generate Paraphrase\",\n",
        "            type=\"primary\",\n",
        "            use_container_width=True,\n",
        "            disabled=not input_text.strip()\n",
        "        )\n",
        "\n",
        "    def add_to_paraphrase_history(original_text, paraphrased_text, model, complexity, style, original_grade, new_grade):\n",
        "        \"\"\"Add current paraphrasing to history\"\"\"\n",
        "        history_entry = {\n",
        "            'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            'original_text': original_text[:100] + \"...\" if len(original_text) > 100 else original_text,\n",
        "            'paraphrased_text': paraphrased_text,\n",
        "            'model': model,\n",
        "            'complexity': complexity,\n",
        "            'style': style,\n",
        "            'original_grade': original_grade,\n",
        "            'new_grade': new_grade,\n",
        "            'improvement': new_grade - original_grade\n",
        "        }\n",
        "        st.session_state.paraphrasing_history.insert(0, history_entry)\n",
        "\n",
        "        # Keep only last 10 entries\n",
        "        if len(st.session_state.paraphrasing_history) > 10:\n",
        "            st.session_state.paraphrasing_history = st.session_state.paraphrasing_history[:10]\n",
        "\n",
        "    def create_complexity_chart(original_grade, new_grade, complexity_level):\n",
        "        \"\"\"Create the exact complexity chart from the screenshot\"\"\"\n",
        "        try:\n",
        "            fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "            # Define the levels and their positions exactly as in screenshot\n",
        "            levels = ['Beginner', 'Intermediate', 'Advanced', 'Expert']\n",
        "            level_positions = [1, 2, 3, 4]  # Vertical positions\n",
        "\n",
        "            # Set up the graph background and styling\n",
        "            ax.set_facecolor('#f8f9fa')\n",
        "            fig.patch.set_facecolor('#f8f9fa')\n",
        "\n",
        "            # Create the main diagonal line (the graph line)\n",
        "            x_points = [5, 6, 7, 8, 9]\n",
        "            y_points = [1, 2, 3, 4, 5]  # Slightly offset for visual appeal\n",
        "\n",
        "            # Plot the diagonal graph line\n",
        "            ax.plot(x_points, y_points, color='#0d6efd', linewidth=3, marker='o',\n",
        "                    markersize=8, markerfacecolor='white', markeredgecolor='#0d6efd',\n",
        "                    markeredgewidth=2)\n",
        "\n",
        "            # Add level labels on the left side (like in screenshot)\n",
        "            for level, pos in zip(levels, level_positions):\n",
        "                ax.text(4.7, pos, level, ha='right', va='center',\n",
        "                       fontweight='bold', fontsize=11, color='#495057')\n",
        "\n",
        "            # Add \"Graph Level\" title on the left\n",
        "            ax.text(4.7, 4.8, 'Graph Level', ha='right', va='center',\n",
        "                   fontweight='bold', fontsize=12, color='#212529')\n",
        "\n",
        "            # Add \"Graph\" label above the line\n",
        "            ax.text(7, 5.2, 'Graph', ha='center', va='center',\n",
        "                   fontweight='bold', fontsize=11, color='#212529')\n",
        "\n",
        "            # Add \"Diagonal\" label\n",
        "            ax.text(7, 0.7, 'Diagonal', ha='center', va='center',\n",
        "                   fontstyle='italic', fontsize=10, color='#6c757d')\n",
        "\n",
        "            # Add \"Diagrams\" label (positioned similarly to screenshot)\n",
        "            ax.text(8.5, 3.5, 'Diagrams', ha='center', va='center',\n",
        "                   fontstyle='italic', fontsize=10, color='#6c757d', rotation=-45)\n",
        "\n",
        "            # Add \"Intermediate\" indicator (the main focus point)\n",
        "            intermediate_x = 7\n",
        "            intermediate_y = 3\n",
        "            ax.plot(intermediate_x, intermediate_y, 's', markersize=12,\n",
        "                    color='#dc3545', markerfacecolor='#dc3545')\n",
        "\n",
        "            # Add \"Intermediate\" text label\n",
        "            ax.text(7.3, 3, 'Intermediate', ha='left', va='center',\n",
        "                   fontweight='bold', fontsize=10, color='#dc3545')\n",
        "\n",
        "            # Add \"Acknowledgment\" text\n",
        "            ax.text(5.5, 0.4, 'Acknowledgment', ha='center', va='center',\n",
        "                   fontsize=9, color='#6c757d')\n",
        "\n",
        "            # Set axis limits and labels\n",
        "            ax.set_xlim(4.5, 9.5)\n",
        "            ax.set_ylim(0.5, 5.5)\n",
        "\n",
        "            # Remove axes spines and ticks\n",
        "            ax.spines['top'].set_visible(False)\n",
        "            ax.spines['right'].set_visible(False)\n",
        "            ax.spines['left'].set_visible(False)\n",
        "            ax.spines['bottom'].set_visible(False)\n",
        "\n",
        "            # Remove ticks\n",
        "            ax.set_xticks([])\n",
        "            ax.set_yticks([])\n",
        "\n",
        "            # Add grid lines for better readability (subtle)\n",
        "            ax.grid(True, alpha=0.2, linestyle='-', color='#adb5bd')\n",
        "\n",
        "            # Add a subtle border\n",
        "            rect = plt.Rectangle((4.5, 0.5), 5, 5, linewidth=1, edgecolor='#dee2e6',\n",
        "                               facecolor='none', linestyle='-')\n",
        "            ax.add_patch(rect)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            return fig\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error creating complexity chart: {e}\")\n",
        "            return None\n",
        "\n",
        "    # Main paraphrasing logic\n",
        "    if generate_clicked and input_text.strip():\n",
        "        if paraphrase_model is None:\n",
        "            st.error(\"‚ùå Paraphrase model not loaded. Please refresh the page.\")\n",
        "        else:\n",
        "            with st.spinner(f\"Generating {complexity_level.lower()} paraphrase using {model_type}...\"):\n",
        "                start_time = time.time()\n",
        "                # Use local model instead of API\n",
        "                paraphrased_text = local_paraphrase(\n",
        "                    paraphrase_model, paraphrase_tokenizer, input_text, complexity_level, paraphrasing_style\n",
        "                )\n",
        "                end_time = time.time()\n",
        "\n",
        "                original_grade = calculate_flesch_kincaid_para(input_text)\n",
        "                new_grade = calculate_flesch_kincaid_para(paraphrased_text)\n",
        "\n",
        "                # Add to history\n",
        "                add_to_paraphrase_history(\n",
        "                    input_text, paraphrased_text, model_type, complexity_level,\n",
        "                    paraphrasing_style, original_grade, new_grade\n",
        "                )\n",
        "\n",
        "                # Display results\n",
        "                st.markdown(\"---\")\n",
        "                st.subheader(\"üìä Paraphrase Results\")\n",
        "\n",
        "                # Side-by-side comparison\n",
        "                col1, col2 = st.columns(2)\n",
        "\n",
        "                with col1:\n",
        "                    st.markdown(\"**Original Text**\")\n",
        "                    st.markdown(f\"**Grade Level: {original_grade:.1f}**\")\n",
        "                    st.info(input_text)\n",
        "\n",
        "                with col2:\n",
        "                    st.markdown(\"**Paraphrased Text**\")\n",
        "                    st.markdown(f\"**Grade Level: {new_grade:.1f}**\")\n",
        "                    st.success(paraphrased_text)\n",
        "\n",
        "                # Complexity visualization\n",
        "                st.markdown(\"---\")\n",
        "                st.subheader(\"üìà Complexity Visualization\")\n",
        "\n",
        "                complexity_chart = create_complexity_chart(original_grade, new_grade, complexity_level)\n",
        "                if complexity_chart:\n",
        "                    st.pyplot(complexity_chart)\n",
        "\n",
        "                # Grade level interpretation\n",
        "                st.markdown(\"---\")\n",
        "                st.subheader(\"üìñ Grade Level Interpretation\")\n",
        "\n",
        "                col1, col2, col3, col4 = st.columns(4)\n",
        "\n",
        "                with col1:\n",
        "                    st.metric(\"Original Grade\", f\"{original_grade:.1f}\")\n",
        "                with col2:\n",
        "                    st.metric(\"New Grade\", f\"{new_grade:.1f}\")\n",
        "                with col3:\n",
        "                    change = new_grade - original_grade\n",
        "                    st.metric(\"Change\", f\"{change:+.1f}\")\n",
        "                with col4:\n",
        "                    if abs(change) <= 1:\n",
        "                        st.metric(\"Impact\", \"Minimal\")\n",
        "                    elif abs(change) <= 3:\n",
        "                        st.metric(\"Impact\", \"Moderate\")\n",
        "                    else:\n",
        "                        st.metric(\"Impact\", \"Significant\")\n",
        "\n",
        "                # Show performance info\n",
        "                st.info(f\"‚è±Ô∏è Generated in {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "                # Detailed interpretation\n",
        "                with st.expander(\"üí° Understanding Grade Levels\"):\n",
        "                    st.markdown(\"\"\"\n",
        "                    **Grade Level Interpretation Guide:**\n",
        "\n",
        "                    - **1-4**: Elementary school level\n",
        "                    - **5-8**: Middle school level\n",
        "                    - **9-12**: High school level\n",
        "                    - **13-16**: College level\n",
        "                    - **17-20**: Graduate/professional level\n",
        "\n",
        "                    **Complexity Adjustment:**\n",
        "                    - **Negative change**: Text simplified\n",
        "                    - **Positive change**: Text made more complex\n",
        "                    - **Minimal change**: Complexity maintained\n",
        "                    \"\"\")\n",
        "\n",
        "    elif generate_clicked and not input_text.strip():\n",
        "        st.warning(\"Please enter some text or upload a file to paraphrase.\")\n",
        "\n",
        "    # History section\n",
        "    st.markdown(\"---\")\n",
        "    st.subheader(\"üìú Paraphrasing History\")\n",
        "\n",
        "    if st.session_state.paraphrasing_history:\n",
        "        history_data = []\n",
        "        for entry in st.session_state.paraphrasing_history:\n",
        "            history_data.append({\n",
        "                'Timestamp': entry['timestamp'],\n",
        "                'Model': entry['model'],\n",
        "                'Complexity': entry['complexity'],\n",
        "                'Style': entry['style'],\n",
        "                'Original Grade': f\"{entry['original_grade']:.1f}\",\n",
        "                'New Grade': f\"{entry['new_grade']:.1f}\",\n",
        "                'Change': f\"{entry['improvement']:+.1f}\"\n",
        "            })\n",
        "\n",
        "        history_df = pd.DataFrame(history_data)\n",
        "        st.dataframe(history_df, use_container_width=True)\n",
        "\n",
        "        # Clear history button\n",
        "        if st.button(\"Clear History\", type=\"secondary\"):\n",
        "            st.session_state.paraphrasing_history = []\n",
        "            st.rerun()\n",
        "    else:\n",
        "        st.info(\"No paraphrasing history yet. Generate some paraphrases to see them here!\")\n",
        "\n",
        "    # Key Features section\n",
        "    st.markdown(\"---\")\n",
        "    st.subheader(\"üîë Key Features\")\n",
        "\n",
        "    feature_col1, feature_col2, feature_col3 = st.columns(3)\n",
        "\n",
        "    with feature_col1:\n",
        "        st.markdown(\"\"\"\n",
        "        **ü§ñ Advanced NLP Models**\n",
        "        - FLAN-T5: Instruction-tuned paraphrasing\n",
        "        - BART: Denoising autoencoder\n",
        "        - Multi-level complexity adjustment\n",
        "        \"\"\")\n",
        "\n",
        "    with feature_col2:\n",
        "        st.markdown(\"\"\"\n",
        "        **üéØ Targeted Complexity**\n",
        "        - Beginner: Simple language\n",
        "        - Intermediate: Balanced complexity\n",
        "        - Advanced: Sophisticated vocabulary\n",
        "        - Expert: Professional/technical\n",
        "        \"\"\")\n",
        "\n",
        "    with feature_col3:\n",
        "        st.markdown(\"\"\"\n",
        "        **üìä Visual Analytics**\n",
        "        - Grade level comparison\n",
        "        - Complexity progression charts\n",
        "        - Side-by-side text comparison\n",
        "        \"\"\")\n",
        "\n",
        "# =============================================================================\n",
        "#  UI SECTION: CHAT INTERFACE (PLACEHOLDER)\n",
        "# =============================================================================\n",
        "\n",
        "def chat_interface():\n",
        "    st.title(\"üí¨ Chat with AI\")\n",
        "    st.info(\"üöß This feature is under development\")\n",
        "    st.write(\"\"\"\n",
        "    Interactive chat interface for:\n",
        "\n",
        "    - **Text Analysis**: Ask questions about your documents\n",
        "    - **Writing Assistance**: Get help with writing and editing\n",
        "    - **Content Generation**: Create new content based on your needs\n",
        "    - **Learning Support**: Get explanations and insights\n",
        "\n",
        "    Start a conversation with our AI assistant!\n",
        "    \"\"\")\n",
        "\n",
        "    # Placeholder for future implementation\n",
        "    if \"chat_messages\" not in st.session_state:\n",
        "        st.session_state.chat_messages = []\n",
        "\n",
        "    for message in st.session_state.chat_messages:\n",
        "        with st.chat_message(message[\"role\"]):\n",
        "            st.write(message[\"content\"])\n",
        "\n",
        "    if prompt := st.chat_input(\"Ask me anything...\"):\n",
        "        st.session_state.chat_messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "        with st.chat_message(\"user\"):\n",
        "            st.write(prompt)\n",
        "\n",
        "        # Simulate AI response\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            st.write(\"This is a simulated response. The chat feature is currently under development.\")\n",
        "\n",
        "# =============================================================================\n",
        "#  UI SECTION: ADMIN DASHBOARD\n",
        "# =============================================================================\n",
        "\n",
        "def admin_dashboard():\n",
        "    st.title(\"üëë Admin Dashboard\")\n",
        "    tab1, tab2 = st.tabs([\"User Management\", \"App Analytics (Placeholder)\"])\n",
        "    with tab1:\n",
        "        st.subheader(\"User Database\")\n",
        "        users_df = get_all_users()\n",
        "        st.dataframe(users_df, use_container_width=True)\n",
        "        col1, col2 = st.columns(2)\n",
        "        with col1:\n",
        "            with st.form(\"add_user_form\", clear_on_submit=True):\n",
        "                st.subheader(\"‚ûï Add New User\")\n",
        "                new_email = st.text_input(\"New User Email\")\n",
        "                new_password = st.text_input(\"New User Password\", type=\"password\")\n",
        "                new_role = st.selectbox(\"Assign Role\", [\"General User\", \"Admin\"])\n",
        "                if st.form_submit_button(\"Add User\"):\n",
        "                    if new_email and new_password:\n",
        "                        message = register_user(new_email, new_password, new_role)\n",
        "                        st.success(message)\n",
        "                        st.rerun()\n",
        "                    else:\n",
        "                        st.error(\"Please fill in all fields.\")\n",
        "        with col2:\n",
        "            with st.form(\"delete_user_form\", clear_on_submit=True):\n",
        "                st.subheader(\"‚ö†Ô∏è Delete User\")\n",
        "                user_to_delete = st.selectbox(\"Select User to Delete\", options=users_df['email'].tolist())\n",
        "                if st.form_submit_button(\"Delete User\", type=\"primary\"):\n",
        "                    delete_user(user_to_delete)\n",
        "                    st.warning(f\"User '{user_to_delete}' deleted.\")\n",
        "                    st.rerun()\n",
        "    with tab2:\n",
        "        st.subheader(\"Application Analytics\")\n",
        "        st.metric(\"Total Users\", len(get_all_users()))\n",
        "        st.metric(\"Daily Active Users (Mock)\", \"123\")\n",
        "        chart_data = pd.DataFrame(np.random.randn(20, 3), columns=['A', 'B', 'C'])\n",
        "        st.line_chart(chart_data)\n",
        "\n",
        "# =============================================================================\n",
        "#  NAVIGATION FUNCTION\n",
        "# =============================================================================\n",
        "def render_navigation():\n",
        "    \"\"\"Render the navigation menu in sidebar\"\"\"\n",
        "    payload = decode_token(st.session_state.token)\n",
        "\n",
        "    if payload and payload['role'].lower() == 'admin':\n",
        "        # For admin users - only show Settings and Logout, no navigation menu\n",
        "        st.sidebar.markdown(\"## üëë Admin Panel\")\n",
        "        st.sidebar.info(\"Admins have access to all features through the Admin Dashboard\")\n",
        "    else:\n",
        "        # For regular users - show full navigation menu\n",
        "        st.sidebar.markdown(\"## üì± Navigation\")\n",
        "\n",
        "        # Navigation options for regular users\n",
        "        nav_options = {\n",
        "            \"üìä Dashboard & Readability Analysis\": \"dashboard\",\n",
        "            \"üìù Multi-level Summarization\": \"summarization\",\n",
        "            \"üîÑ Complexity-based Paraphrasing\": \"paraphrasing\",\n",
        "            \"üí¨ Chat\": \"chat\"\n",
        "        }\n",
        "\n",
        "        # Create navigation buttons\n",
        "        for option, key in nav_options.items():\n",
        "            if st.sidebar.button(option, key=f\"nav_{key}\", use_container_width=True):\n",
        "                st.session_state.current_page = key\n",
        "\n",
        "        st.sidebar.markdown(\"---\")\n",
        "\n",
        "# =============================================================================\n",
        "#  MAIN AUTHENTICATION ROUTER\n",
        "# =============================================================================\n",
        "\n",
        "if 'token' not in st.session_state:\n",
        "    st.session_state.token = None\n",
        "if 'theme' not in st.session_state:\n",
        "    st.session_state.theme = \"Light\"\n",
        "if 'current_page' not in st.session_state:\n",
        "    st.session_state.current_page = \"dashboard\"\n",
        "if 'forgot_password_stage' not in st.session_state:\n",
        "    st.session_state.forgot_password_stage = \"request\"\n",
        "\n",
        "# Initialize model histories\n",
        "if 'summarization_history' not in st.session_state:\n",
        "    st.session_state.summarization_history = []\n",
        "if 'paraphrasing_history' not in st.session_state:\n",
        "    st.session_state.paraphrasing_history = []\n",
        "\n",
        "payload = decode_token(st.session_state.token)\n",
        "\n",
        "if payload is None:\n",
        "    st.session_state.token = None\n",
        "    # --- UPDATED: Use columns to center the login form ---\n",
        "    st.markdown(\"<style>div[data-testid='stHorizontalBlock'] { text-align: center; }</style>\", unsafe_allow_html=True)\n",
        "    _ , main_content, _ = st.columns([1, 1.5, 1])\n",
        "    with main_content:\n",
        "        st.markdown(\"<h1>‚û° User Authentication</h1>\", unsafe_allow_html=True)\n",
        "        login_tab, register_tab, forgot_tab = st.tabs([\"Login\", \"Register\", \"Forgot Password\"])\n",
        "        with login_tab:\n",
        "            with st.form(\"login_form\"):\n",
        "                email = st.text_input(\"Email\", placeholder=\"Enter your Email\")\n",
        "                password = st.text_input(\"Password\", type=\"password\", placeholder=\"*****\")\n",
        "                if st.form_submit_button(\"Sign In\"):\n",
        "                    token = authenticate_user(email, password)\n",
        "                    if token:\n",
        "                        st.session_state.token = token\n",
        "                        st.rerun()\n",
        "                    else:\n",
        "                        st.error(\"Invalid email or password.\")\n",
        "        # --- UPDATED: Added full registration logic ---\n",
        "        with register_tab:\n",
        "            with st.form(\"register_form\"):\n",
        "                new_email = st.text_input(\"Email\", key=\"reg_email\")\n",
        "                new_password = st.text_input(\"New Password\", type=\"password\", key=\"reg_pass\")\n",
        "                confirm_password = st.text_input(\"Confirm Password\", type=\"password\", key=\"reg_confirm\")\n",
        "                role = st.selectbox(\"Role\", [\"General User\", \"Admin\"])\n",
        "                if st.form_submit_button(\"Register\"):\n",
        "                    if new_password == confirm_password:\n",
        "                        message = register_user(new_email, new_password, role)\n",
        "                        if \"successfully\" in message:\n",
        "                            st.success(message)\n",
        "                        else:\n",
        "                            st.warning(message)\n",
        "                    else:\n",
        "                        st.error(\"Passwords do not match.\")\n",
        "        with forgot_tab:\n",
        "            forgot_password_flow()\n",
        "else:\n",
        "    role = payload['role']\n",
        "    with st.sidebar:\n",
        "        st.success(f\"Logged in as: {payload['sub']}\")\n",
        "        st.write(f\"Your role is: **{role}**\")\n",
        "\n",
        "        # Render navigation menu\n",
        "        render_navigation()\n",
        "\n",
        "        if st.button(\"Logout\"):\n",
        "            st.session_state.token = None\n",
        "            st.rerun()\n",
        "        st.markdown(\"---\")\n",
        "        with st.expander(\"‚öôÔ∏è Settings\"):\n",
        "            st.session_state.theme = st.radio(\"Theme\", [\"Light\", \"Dark\"])\n",
        "\n",
        "    if st.session_state.theme == \"Dark\":\n",
        "        st.markdown(dark_theme_css, unsafe_allow_html=True)\n",
        "\n",
        "    # Page routing based on navigation\n",
        "    if role.lower() == \"admin\":\n",
        "        admin_dashboard()\n",
        "    else:\n",
        "        if st.session_state.current_page == \"dashboard\":\n",
        "            readability_dashboard()\n",
        "        elif st.session_state.current_page == \"summarization\":\n",
        "            multi_level_summarization()\n",
        "        elif st.session_state.current_page == \"paraphrasing\":\n",
        "            complexity_paraphrasing()\n",
        "        elif st.session_state.current_page == \"chat\":\n",
        "            chat_interface()\n",
        "        else:\n",
        "            readability_dashboard()  # Default page"
      ],
      "metadata": {},
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app1.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SECTION 3: Running StreamLit"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with your actual ngrok authtoken\n",
        "!ngrok config add-authtoken 34Nkqo7OM708MU0EvgUjzlPSEt2_84PRCVh5FgpuKVEQiYgLX\n",
        "ngrok.kill()\n",
        "\n",
        "public_url = ngrok.connect(8502)\n",
        "print(f\"üåç Public URL: {public_url}\")\n",
        "!streamlit run app1.py --server.port 8502 --server.headless true"
      ],
      "metadata": {},
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "üåç Public URL: NgrokTunnel: \"https://subcultural-kimberli-unretrogressively.ngrok-free.dev\" -> \"http://localhost:8502\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8502\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8502\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://136.117.156.218:8502\u001b[0m\n",
            "\u001b[0m\n",
            "2025-10-28 12:36:28.817930: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761654988.882608     808 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761654988.898165     808 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761654988.938224     808 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761654988.938271     808 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761654988.938278     808 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761654988.938284     808 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-28 12:36:28.947134: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/content/app1.py:392: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  payload = {'exp': datetime.utcnow() + timedelta(hours=1), 'iat': datetime.utcnow(), 'sub': email, 'role': role}\n",
            "tokenizer_config.json: 100% 2.32k/2.32k [00:00<00:00, 10.4MB/s]\n",
            "spiece.model: 100% 792k/792k [00:00<00:00, 4.18MB/s]\n",
            "tokenizer.json: 100% 1.39M/1.39M [00:00<00:00, 6.94MB/s]\n",
            "config.json: 100% 1.21k/1.21k [00:00<00:00, 5.66MB/s]\n",
            "model.safetensors: 100% 242M/242M [00:02<00:00, 100MB/s]\n",
            "generation_config.json: 100% 147/147 [00:00<00:00, 694kB/s]\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "Exception ignored in: <module 'threading' from '/usr/lib/python3.12/threading.py'>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1624, in _shutdown\n",
            "    lock.acquire()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/streamlit/web/bootstrap.py\", line 42, in signal_handler\n",
            "    server.stop()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/streamlit/web/server/server.py\", line 510, in stop\n",
            "    self._runtime.stop()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/streamlit/runtime/runtime.py\", line 329, in stop\n",
            "    async_objs.eventloop.call_soon_threadsafe(stop_on_eventloop)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 844, in call_soon_threadsafe\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "Exception ignored in atexit callback: <function dump_compile_times at 0x7c1127b81580>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/utils.py\", line 811, in dump_compile_times\n",
            "    log.info(compile_times(repr=\"str\", aggregate=True))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/utils.py\", line 797, in compile_times\n",
            "    out += tabulate(rows, headers=(\"Function\", \"Runtimes (s)\"))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/utils.py\", line 226, in tabulate\n",
            "    import tabulate\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/streamlit/web/bootstrap.py\", line 42, in signal_handler\n",
            "    server.stop()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/streamlit/web/server/server.py\", line 510, in stop\n",
            "    self._runtime.stop()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/streamlit/runtime/runtime.py\", line 329, in stop\n",
            "    async_objs.eventloop.call_soon_threadsafe(stop_on_eventloop)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 844, in call_soon_threadsafe\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}